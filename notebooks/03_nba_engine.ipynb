{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2f68ab5",
   "metadata": {},
   "source": [
    "# ***NBA Engine***\n",
    "Via LLM Reasoning (Local LLama Model)\n",
    "\n",
    "| Requirement                 | You Should Do                                     |\n",
    "| --------------------------- | ------------------------------------------------- |\n",
    "| Choose a channel            | Based on behavior, flow, and history              |\n",
    "| Pick best send time         | Based on customer activity (heuristic or learned) |\n",
    "| Generate a response message | Personalized or templated                         |\n",
    "| Explain your reasoning      | Why this action fits this customer                |\n",
    "| Output JSON                 | Fully reproducible, structured format             |\n",
    "| Justify method              | Why LLM is best                 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782512d4",
   "metadata": {},
   "source": [
    "## **Llama 3.2 using Langchain wrapping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ccf4a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66964d13",
   "metadata": {},
   "source": [
    "## **Clean Unified feed after user behaviour analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e9c7586",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"..\\outputs\\json\\parsed_conversations_tagged_summary_clustered.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    all_conversations = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b626d972",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"llama3.2\", base_url=\"http://localhost:11434\", temperature=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e329335f",
   "metadata": {},
   "source": [
    "## **Response Schema and Output Parser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b58a747",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_schemas = [\n",
    "    ResponseSchema(name=\"customer_id\", description=\"Customer ID\"),\n",
    "    ResponseSchema(name=\"channel\", description=\"Best communication channel: twitter_dm_reply, scheduling_phone_call, or email_reply\"),\n",
    "    ResponseSchema(name=\"send_time\", description=\"Best time to send message, in ISO format (UTC)\"),\n",
    "    ResponseSchema(name=\"message\", description=\"The actual message to send\"),\n",
    "    ResponseSchema(name=\"reasoning\", description=\"Why this channel/time/message was chosen\"),\n",
    "    ResponseSchema(name=\"resolved\", description=\"true if customer issue seems resolved, else false\")\n",
    "]\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ac40f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_prompt_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You are an intelligent reasoning agent for Next Best Action (NBA) in customer support.\n",
    "\n",
    "Your task is to recommend:\n",
    "1. Best channel (twitter_dm_reply, scheduling_phone_call, or email_reply)\n",
    "2. Best send time in UTC (consider customer activity & urgency)\n",
    "3. A helpful, personalized response message\n",
    "4. Reasoning behind your decision\n",
    "5. Whether the issue appears resolved\n",
    "\n",
    "---\n",
    "\n",
    "You are provided a customer conversation flow with detailed behavior and analysis:\n",
    "\n",
    "### Features Available\n",
    "\n",
    "**trajectory_category** → whether user's mood is improving, worsening, or mixed/stable\n",
    "**Conversation Summary:**\n",
    "- Customer ID: {customer_id}\n",
    "- Agent ID: {agent_id}\n",
    "- Total User Turns: {num_user_turns}\n",
    "- Total Agent Turns: {num_agent_turns}\n",
    "- Average Sentiment Confidence: {avg_sentiment_confidence:.2f}\n",
    "- Median Sentiment Confidence: {median_sentiment_confidence:.2f}\n",
    "- Avg Response Gap (seconds): {avg_response_gap_seconds:.2f}\n",
    "- Fine-Grained Issue: {fine_grained_issue}\n",
    "- High-Level Issue: {high_level_issue}\n",
    "- Sentiment Trajectory Category: {trajectory_category}\n",
    "- Flow Cluster ID: {flow_cluster}\n",
    "\n",
    "**Conversation Text Snippets**:\n",
    "{conversation_text}\n",
    "\n",
    "---\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Choose the most appropriate **channel**:\n",
    "  - Use `twitter_dm_reply` if conversation is live and active\n",
    "  - Use `scheduling_phone_call` for high-stakes/confusing/urgent problems\n",
    "  - Use `email_reply` if sentiment has stabilized, or issue is resolved\n",
    "\n",
    "- Pick best **send_time** in UTC (based on timestamps or urgency)\n",
    "\n",
    "- Compose a helpful **message** (solve or clarify)\n",
    "\n",
    "- Provide clear **reasoning**\n",
    "\n",
    "- Set `resolved = true` only if user’s last message shows satisfaction\n",
    "\n",
    "---\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\",\n",
    "    input_variables=[\n",
    "        \"customer_id\", \"agent_id\", \"num_user_turns\", \"num_agent_turns\",\n",
    "        \"avg_sentiment_confidence\", \"median_sentiment_confidence\",\n",
    "        \"avg_response_gap_seconds\", \"fine_grained_issue\", \"high_level_issue\",\n",
    "        \"trajectory_category\", \"flow_cluster\", \"conversation_text\"\n",
    "    ],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47e7ddb",
   "metadata": {},
   "source": [
    "## **NBA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57db56dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from dateutil import parser\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from tqdm import tqdm\n",
    "\n",
    "nba_records = []\n",
    "nba_outputs = []\n",
    "\n",
    "def generate_nba_instruction(convo):\n",
    "    summary = convo.get(\"flow_summary\", {})\n",
    "    original_messages = copy.deepcopy(convo.get(\"conversation\", [])) \n",
    "    messages = convo.get(\"conversation\", [])\n",
    "    customer_id = convo.get(\"customer_id\")\n",
    "    agent_id = convo.get(\"agent_id\")\n",
    "    flow_cluster = convo.get(\"flow_cluster\", -1)\n",
    "\n",
    "\n",
    "    conversation_text = \"\\n\".join([\n",
    "        f\"{m['sender'].capitalize()}: {m['text']}\" for m in original_messages if 'text' in m\n",
    "    ])\n",
    "\n",
    "    prompt_input = {\n",
    "        \"customer_id\": customer_id,\n",
    "        \"agent_id\": agent_id,\n",
    "        \"num_user_turns\": summary.get(\"num_user_turns\", 0),\n",
    "        \"num_agent_turns\": summary.get(\"num_agent_turns\", 0),\n",
    "        \"avg_sentiment_confidence\": summary.get(\"avg_sentiment_confidence\", 0.0),\n",
    "        \"median_sentiment_confidence\": summary.get(\"median_sentiment_confidence\", 0.0),\n",
    "        \"avg_response_gap_seconds\": summary.get(\"avg_response_gap_seconds\", 0.0),\n",
    "        \"fine_grained_issue\": summary.get(\"fine_grained_issue\", \"\"),\n",
    "        \"high_level_issue\": summary.get(\"high_level_issue\", \"\"),\n",
    "        \"trajectory_category\": summary.get(\"trajectory_category\", \"stable\"),\n",
    "        \"flow_cluster\": flow_cluster,\n",
    "        \"conversation_text\": conversation_text\n",
    "    }\n",
    "\n",
    "    # Prompt LLM\n",
    "    prompt = nba_prompt_template.format(**prompt_input)\n",
    "    response = llm.invoke(prompt)\n",
    "    response_content = getattr(response, \"content\", None)\n",
    "    if not isinstance(response_content, str):\n",
    "        raise ValueError(f\"Invalid LLM response type: {type(response_content)}\")\n",
    "\n",
    "    parsed_output = output_parser.parse(response_content)\n",
    "\n",
    "    # Clamping send_time\n",
    "    now_utc = datetime.now(timezone.utc)\n",
    "    max_send_dt = now_utc + timedelta(days=2)\n",
    "\n",
    "    try:\n",
    "        parsed_send_dt = parser.parse(parsed_output[\"send_time\"])\n",
    "        if parsed_send_dt.tzinfo is None:\n",
    "            parsed_send_dt = parsed_send_dt.replace(tzinfo=timezone.utc)\n",
    "    except Exception:\n",
    "        parsed_send_dt = now_utc + timedelta(hours=1)\n",
    "\n",
    "    safe_day = min((now_utc + timedelta(days=2)).day, 28)\n",
    "    final_send_dt = parsed_send_dt.replace(\n",
    "        year=now_utc.year,\n",
    "        month=now_utc.month,\n",
    "        day=safe_day\n",
    "    )\n",
    "    if final_send_dt > max_send_dt:\n",
    "        final_send_dt = max_send_dt\n",
    "\n",
    "    parsed_output[\"send_time\"] = final_send_dt.isoformat().replace(\"+00:00\", \"Z\")\n",
    "\n",
    "    # Appending new message to conversation\n",
    "    convo[\"conversation\"].append({\n",
    "        \"sender\": \"agent\",\n",
    "        \"text\": parsed_output[\"message\"],\n",
    "        \"timestamp\": parsed_output[\"send_time\"]\n",
    "    })\n",
    "\n",
    "    # only original messages for chat log\n",
    "    chat_log = \"\\n\".join([\n",
    "        f\"{m['sender'].capitalize()}: {m['text']}\" for m in original_messages\n",
    "    ])\n",
    "\n",
    "    nba_records.append({\n",
    "        \"customer_id\": customer_id,\n",
    "        \"chat_log\": chat_log,\n",
    "        \"channel\": parsed_output[\"channel\"],\n",
    "        \"message\": parsed_output[\"message\"],\n",
    "        \"send_time\": parsed_output[\"send_time\"],\n",
    "        \"reasoning\": parsed_output[\"reasoning\"],\n",
    "        \"issue_status\": \"resolved\" if parsed_output[\"resolved\"] else \"pending_customer_response\"\n",
    "    })\n",
    "\n",
    "    return convo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd07c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [36:49<06:07, 183.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for customer 245869: Got invalid return object. Expected key `resolved` to be present, but got {'customer_id': '245869', 'channel': 'email_reply', 'send_time': '2023-03-08T14:30:00+00:00', 'message': \"Thank you for sharing your concerns about the iPhone notifications. We apologize for any inconvenience this has caused and are happy to help you find a solution. Can you please tell us more about what's happening with your iPhone?\", 'reasoning': \"Given that the customer's sentiment trajectory category is 'stable' and their fine-grained issue is 'feedback', it suggests that they have cooled down and are looking for a resolution. Since there is no urgent or high-stakes issue, an email reply is the most suitable channel to provide a helpful response without overwhelming them with a phone call.\"}\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [38:32<00:00, 115.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for customer 122826: Got invalid return object. Expected key `resolved` to be present, but got {'customer_id': '122826', 'channel': 'twitter_dm_reply', 'send_time': '2023-03-08T14:30:00Z', 'message': \"Thank you so much for your kind words about our staff and airline! We're thrilled to have made a positive impression on your first flight with us. Your loyalty means the world to us!\", 'reasoning': \"Given that the customer's sentiment has stabilized at 'stable' and they've expressed their satisfaction with our staff, I chose Twitter DM Reply as the best channel. The send time is 14:30 UTC, which allows for a timely response while also considering the user's recent activity. The message aims to acknowledge and extend gratitude for their positive experience, further solidifying the positive sentiment.\"}\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for convo in tqdm(all_conversations[5:25]):\n",
    "    try:\n",
    "        nba_output = generate_nba_instruction(convo)\n",
    "        nba_outputs.append(nba_output)\n",
    "    except Exception as e:\n",
    "        print(f\"Error for customer {convo.get('customer_id', 'unknown')}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477bf3e3",
   "metadata": {},
   "source": [
    "## **Saving Ouputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4dc6a9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Save updated conversations\n",
    "with open(r\"..\\outputs\\json\\nba_conversations_updated.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(nba_outputs, f, indent=2)\n",
    "\n",
    "# Save NBA table\n",
    "pd.DataFrame(nba_records).to_csv(r\"..\\outputs\\csv\\nba_actions_log.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "riverline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
